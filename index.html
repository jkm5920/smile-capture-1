from IPython.display import display, HTML

# 1. 스마일 캡처 앱의 전체 HTML/JavaScript 코드를 문자열로 정의합니다.
html_code = """
<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>스마일 캡처 앱 (Colab)</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body {
      text-align: center;
      background: #222;
      color: #fff;
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 20px;
    }
    /* 비디오와 캔버스를 겹치기 위한 래퍼 */
    .video-container {
      position: relative;
      width: 320px;
      height: 240px;
      border-radius: 10px;
      overflow: hidden; /* 둥근 모서리를 위해 */
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    button {
      margin-top: 25px; /* 비디오와 간격 띄우기 */
      padding: 10px 20px;
      border: none;
      border-radius: 8px;
      background: #0b84ff;
      color: white;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h2>스마일 캡처 앱</h2>
  <p>웃으면 자동으로 감지돼요!</p>
  
    <div class="video-container">
    <video id="video" width="320" height="240" autoplay muted playsinline></video>
    <canvas id="overlay" width="320" height="240"></canvas>
  </div>
  <button id="capture">사진 저장하기</button>

  <script>
    // DOM 요소 가져오기
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const context = overlay.getContext('2d');

    // 1. AI 모델(가중치) 로드
    Promise.all([
      // 'tinyFaceDetector'는 빠르고 가벼운 얼굴 탐지 모델입니다.
      faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/'),
      // 'faceExpressionNet'은 얼굴 표정을 인식하는 모델입니다.
      faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/')
    ]).then(startVideo); // 모델 로드가 완료되면 비디오 시작

    // 2. 비디오 시작 및 카메라 권한 요청
    function startVideo() {
      console.log("모델 로드 완료, 카메라 시작");
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          // 'video' 태그에 카메라 스트림을 연결
          video.srcObject = stream;
        })
        .catch(err => {
          console.error("카메라 접근 실패:", err);
          alert("카메라 접근에 실패했습니다. 브라우저 설정을 확인해주세요.");
        });
    }

    // 3. 비디오가 재생될 때 얼굴 인식 시작
    video.addEventListener('play', () => {
      console.log("비디오 재생 시작, 얼굴 인식 간격 설정");
      const displaySize = { width: video.width, height: video.height };
      // 캔버스 크기를 비디오에 맞게 설정
      faceapi.matchDimensions(overlay, displaySize);

      // 0.3초마다 얼굴 감지 실행
      setInterval(async () => {
        // 얼굴 및 표정 감지
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        
        // 감지 결과를 캔버스 크기에 맞게 리사이즈
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        
        // 캔버스를 지우고 새로 그리기
        context.clearRect(0, 0, overlay.width, overlay.height);
        // 감지된 얼굴에 사각형 그리기
        faceapi.draw.drawDetections(overlay, resizedDetections);
        // 감지된 표정(happy, sad 등) 그리기
        faceapi.draw.drawFaceExpressions(overlay, resizedDetections);

        // 행복한 표정이 0.9 (90%) 이상일 때 콘솔에 로그
        if (resizedDetections[0] && resizedDetections[0].expressions.happy > 0.9) {
          console.log("Smile detected! 😆");
        }
      }, 300); 
    });

    // 4. 캡처 버튼 클릭 이벤트 (개선된 캡처 방식)
    document.getElementById('capture').addEventListener('click', () => {
      console.log("캡처 버튼 클릭됨");
      // 1. 임시 캔버스 생성
      const captureCanvas = document.createElement('canvas');
      captureCanvas.width = video.width;
      captureCanvas.height = video.height;
      const ctx = captureCanvas.getContext('2d');

      // 2. 임시 캔버스에 현재 비디오 화면을 그림
      ctx.drawImage(video, 0, 0, video.width, video.height);
      
      // 3. 그 위에 얼굴 인식 오버레이(상자, 표정)를 겹쳐서 그림
      ctx.drawImage(overlay, 0, 0, overlay.width, overlay.height);

      // 4. 완성된 이미지를 다운로드
      const link = document.createElement('a');
      link.href = captureCanvas.toDataURL('image/png'); // 임시 캔버스에서 이미지 데이터 추출
      link.download = 'smile_capture.png';
      link.click();
    });
  </script>
</body>
</html>
"""

# 2. Colab 셀의 출력(output) 영역에 HTML 코드를 렌더링합니다.
display(HTML(html_code))
