from IPython.display import display, HTML

# 1. ìŠ¤ë§ˆì¼ ìº¡ì²˜ ì•±ì˜ ì „ì²´ HTML/JavaScript ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
html_code = """
<!DOCTYPE html>
<html lang="ko">
<head>
Â  <meta charset="UTF-8" />
Â  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
Â  <title>ìŠ¤ë§ˆì¼ ìº¡ì²˜ ì•± (Colab)</title>
Â  Â  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
Â  <style>
Â  Â  body {
Â  Â  Â  text-align: center;
Â  Â  Â  background: #222;
Â  Â  Â  color: #fff;
Â  Â  Â  font-family: sans-serif;
Â  Â  Â  display: flex;
Â  Â  Â  flex-direction: column;
Â  Â  Â  align-items: center;
Â  Â  Â  justify-content: center;
Â  Â  Â  padding: 20px;
Â  Â  }
Â  Â  /* ë¹„ë””ì˜¤ì™€ ìº”ë²„ìŠ¤ë¥¼ ê²¹ì¹˜ê¸° ìœ„í•œ ë˜í¼ */
Â  Â  .video-container {
Â  Â  Â  position: relative;
Â  Â  Â  width: 320px;
Â  Â  Â  height: 240px;
Â  Â  Â  border-radius: 10px;
      overflow: hidden; /* ë‘¥ê·¼ ëª¨ì„œë¦¬ë¥¼ ìœ„í•´ */
Â  Â  }
Â  Â  video, canvas {
Â  Â  Â  position: absolute;
Â  Â  Â  top: 0;
Â  Â  Â  left: 0;
Â  Â  }
Â  Â  button {
Â  Â  Â  margin-top: 25px; /* ë¹„ë””ì˜¤ì™€ ê°„ê²© ë„ìš°ê¸° */
Â  Â  Â  padding: 10px 20px;
Â  Â  Â  border: none;
Â  Â  Â  border-radius: 8px;
Â  Â  Â  background: #0b84ff;
Â  Â  Â  color: white;
Â  Â  Â  font-size: 16px;
Â  Â  Â  cursor: pointer;
Â  Â  }
Â  </style>
</head>
<body>
Â  <h2>ìŠ¤ë§ˆì¼ ìº¡ì²˜ ì•±</h2>
Â  <p>ì›ƒìœ¼ë©´ ìë™ìœ¼ë¡œ ê°ì§€ë¼ìš”!</p>
Â  
  Â  <div class="video-container">
Â  Â  <video id="video" width="320" height="240" autoplay muted playsinline></video>
Â  Â  <canvas id="overlay" width="320" height="240"></canvas>
Â  </div>
Â  <button id="capture">ì‚¬ì§„ ì €ì¥í•˜ê¸°</button>

Â  <script>
Â  Â  // DOM ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
    const video = document.getElementById('video');
Â  Â  const overlay = document.getElementById('overlay');
Â  Â  const context = overlay.getContext('2d');

Â  Â  // 1. AI ëª¨ë¸(ê°€ì¤‘ì¹˜) ë¡œë“œ
Â  Â  Promise.all([
      // 'tinyFaceDetector'ëŠ” ë¹ ë¥´ê³  ê°€ë²¼ìš´ ì–¼êµ´ íƒì§€ ëª¨ë¸ì…ë‹ˆë‹¤.
Â  Â  Â  faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/'),
      // 'faceExpressionNet'ì€ ì–¼êµ´ í‘œì •ì„ ì¸ì‹í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
Â  Â  Â  faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/')
Â  Â  ]).then(startVideo); // ëª¨ë¸ ë¡œë“œê°€ ì™„ë£Œë˜ë©´ ë¹„ë””ì˜¤ ì‹œì‘

Â  Â  // 2. ë¹„ë””ì˜¤ ì‹œì‘ ë° ì¹´ë©”ë¼ ê¶Œí•œ ìš”ì²­
Â  Â  function startVideo() {
      console.log("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ, ì¹´ë©”ë¼ ì‹œì‘");
Â  Â  Â  navigator.mediaDevices.getUserMedia({ video: {} })
Â  Â  Â  Â  .then(stream => {
          // 'video' íƒœê·¸ì— ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì—°ê²°
Â  Â  Â  Â  Â  video.srcObject = stream;
Â  Â  Â  Â  })
Â  Â  Â  Â  .catch(err => {
Â  Â  Â  Â  Â  console.error("ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:", err);
Â  Â  Â  Â  Â  alert("ì¹´ë©”ë¼ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
Â  Â  Â  Â  });
Â  Â  }

Â  Â  // 3. ë¹„ë””ì˜¤ê°€ ì¬ìƒë  ë•Œ ì–¼êµ´ ì¸ì‹ ì‹œì‘
Â  Â  video.addEventListener('play', () => {
      console.log("ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘, ì–¼êµ´ ì¸ì‹ ê°„ê²© ì„¤ì •");
Â  Â  Â  const displaySize = { width: video.width, height: video.height };
Â  Â  Â  // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ì— ë§ê²Œ ì„¤ì •
Â  Â  Â  faceapi.matchDimensions(overlay, displaySize);

Â  Â  Â  // 0.3ì´ˆë§ˆë‹¤ ì–¼êµ´ ê°ì§€ ì‹¤í–‰
      setInterval(async () => {
Â  Â  Â  Â  // ì–¼êµ´ ë° í‘œì • ê°ì§€
Â  Â  Â  Â  const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
Â  Â  Â  Â  
Â  Â  Â  Â  // ê°ì§€ ê²°ê³¼ë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
Â  Â  Â  Â  const resizedDetections = faceapi.resizeResults(detections, displaySize);
Â  Â  Â  Â  
Â  Â  Â  Â  // ìº”ë²„ìŠ¤ë¥¼ ì§€ìš°ê³  ìƒˆë¡œ ê·¸ë¦¬ê¸°
Â  Â  Â  Â  context.clearRect(0, 0, overlay.width, overlay.height);
        // ê°ì§€ëœ ì–¼êµ´ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
Â  Â  Â  Â  faceapi.draw.drawDetections(overlay, resizedDetections);
        // ê°ì§€ëœ í‘œì •(happy, sad ë“±) ê·¸ë¦¬ê¸°
Â  Â  Â  Â  faceapi.draw.drawFaceExpressions(overlay, resizedDetections);

Â  Â  Â  Â  // í–‰ë³µí•œ í‘œì •ì´ 0.9 (90%) ì´ìƒì¼ ë•Œ ì½˜ì†”ì— ë¡œê·¸
Â  Â  Â  Â  if (resizedDetections[0] && resizedDetections[0].expressions.happy > 0.9) {
Â  Â  Â  Â  Â  console.log("Smile detected! ğŸ˜†");
Â  Â  Â  Â  }
Â  Â  Â  }, 300); 
Â  Â  });

Â  Â  // 4. ìº¡ì²˜ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ (ê°œì„ ëœ ìº¡ì²˜ ë°©ì‹)
Â  Â  document.getElementById('capture').addEventListener('click', () => {
      console.log("ìº¡ì²˜ ë²„íŠ¼ í´ë¦­ë¨");
Â  Â  Â  // 1. ì„ì‹œ ìº”ë²„ìŠ¤ ìƒì„±
Â  Â  Â  const captureCanvas = document.createElement('canvas');
Â  Â  Â  captureCanvas.width = video.width;
Â  Â  Â  captureCanvas.height = video.height;
Â  Â  Â  const ctx = captureCanvas.getContext('2d');

Â  Â  Â  // 2. ì„ì‹œ ìº”ë²„ìŠ¤ì— í˜„ì¬ ë¹„ë””ì˜¤ í™”ë©´ì„ ê·¸ë¦¼
Â  Â  Â  ctx.drawImage(video, 0, 0, video.width, video.height);
Â  Â  Â  
Â  Â  Â  // 3. ê·¸ ìœ„ì— ì–¼êµ´ ì¸ì‹ ì˜¤ë²„ë ˆì´(ìƒì, í‘œì •)ë¥¼ ê²¹ì³ì„œ ê·¸ë¦¼
Â  Â  Â  ctx.drawImage(overlay, 0, 0, overlay.width, overlay.height);

Â  Â  Â  // 4. ì™„ì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ
Â  Â  Â  const link = document.createElement('a');
Â  Â  Â  link.href = captureCanvas.toDataURL('image/png'); // ì„ì‹œ ìº”ë²„ìŠ¤ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
Â  Â  Â  link.download = 'smile_capture.png';
Â  Â  Â  link.click();
Â  Â  });
Â  </script>
</body>
</html>
"""

# 2. Colab ì…€ì˜ ì¶œë ¥(output) ì˜ì—­ì— HTML ì½”ë“œë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
display(HTML(html_code))
