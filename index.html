<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ìŠ¤ë§ˆì¼ ìº¡ì²˜ ì•±</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body { text-align: center; background: #222; color: #fff; font-family: sans-serif; padding: 20px; }
    .container { max-width: 800px; margin: 0 auto; }
    video, canvas { border: 2px solid #0b84ff; border-radius: 10px; margin: 10px; background: #000; }
    button { margin: 15px 10px; padding: 12px 24px; border: none; border-radius: 8px; background: #0b84ff; color: white; font-size: 16px; cursor: pointer; }
    button:hover { background: #0066cc; }
    button:disabled { background: #666; cursor: not-allowed; }
    .status { margin: 10px 0; padding: 10px; border-radius: 5px; background: #333; }
    .success { background: #2d5a2d; }
    .error { background: #5a2d2d; }
    .warning { background: #5a552d; }
  </style>
</head>
<body>
  <div class="container">
    <h2>ğŸ­ ìŠ¤ë§ˆì¼ ìº¡ì²˜ ì•±</h2>
    <p>ì›ƒìœ¼ë©´ ìë™ìœ¼ë¡œ ê°ì§€ë˜ì–´ ì‚¬ì§„ì„ ì €ì¥í•  ìˆ˜ ìˆì–´ìš”!</p>
    
    <div id="status" class="status">ë¡œë”© ì¤‘...</div>
    
    <div>
      <video id="video" width="400" height="300" autoplay muted playsinline></video>
      <canvas id="overlay" width="400" height="300"></canvas>
    </div>
    
    <div>
      <button id="startCamera">ì¹´ë©”ë¼ ì‹œì‘</button>
      <button id="capture" disabled>ğŸ˜Š ì‚¬ì§„ ì €ì¥í•˜ê¸°</button>
    </div>
    
    <div id="detectionInfo" style="margin-top: 20px;"></div>
  </div>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const context = overlay.getContext('2d');
    const statusDiv = document.getElementById('status');
    const detectionInfo = document.getElementById('detectionInfo');
    const captureBtn = document.getElementById('capture');
    const startCameraBtn = document.getElementById('startCamera');

    let isCameraActive = false;
    let detectionInterval;

    function updateStatus(message, type = '') {
      statusDiv.textContent = message;
      statusDiv.className = `status ${type}`;
    }

    async function loadModels() {
      updateStatus('AI ëª¨ë¸ ë¡œë“œ ì¤‘...', 'warning');
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/'),
          faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/'),
          faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/')
        ]);
        updateStatus('AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.', 'success');
        startCameraBtn.disabled = false;
      } catch (error) {
        updateStatus('ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ' + error.message, 'error');
      }
    }

    async function startCamera() {
      if (isCameraActive) return;
      
      updateStatus('ì¹´ë©”ë¼ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­ ì¤‘...', 'warning');
      
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 400 },
            height: { ideal: 300 },
            facingMode: 'user'
          },
          audio: false 
        });
        
        video.srcObject = stream;
        isCameraActive = true;
        startCameraBtn.disabled = true;
        captureBtn.disabled = false;
        updateStatus('ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ! ì–¼êµ´ì„ ì¸ì‹ ì¤‘...', 'success');
        startFaceDetection();
        
      } catch (error) {
        updateStatus('ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: ' + error.message, 'error');
      }
    }

    function startFaceDetection() {
      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(overlay, displaySize);
      
      detectionInterval = setInterval(async () => {
        if (video.paused || video.ended) return;
        
        try {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceExpressions();
          
          context.clearRect(0, 0, overlay.width, overlay.height);
          const resizedDetections = faceapi.resizeResults(detections, displaySize);
          
          faceapi.draw.drawDetections(overlay, resizedDetections);
          faceapi.draw.drawFaceLandmarks(overlay, resizedDetections);
          faceapi.draw.drawFaceExpressions(overlay, resizedDetections);
          
          updateDetectionInfo(detections);
          
          if (detections.length > 0) {
            const expressions = detections[0].expressions;
            const smileConfidence = expressions.happy;
            
            if (smileConfidence > 0.8) {
              captureBtn.style.background = '#ff4444';
              captureBtn.innerHTML = 'ğŸ˜„ ì›ƒëŠ” ì–¼êµ´ ê°ì§€ë¨!';
            } else {
              captureBtn.style.background = '#0b84ff';
              captureBtn.innerHTML = 'ğŸ˜Š ì‚¬ì§„ ì €ì¥í•˜ê¸°';
            }
          }
          
        } catch (error) {
          console.error('Face detection error:', error);
        }
      }, 300);
    }

    function updateDetectionInfo(detections) {
      if (detections.length === 0) {
        detectionInfo.innerHTML = '<p>ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì•ìœ¼ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.</p>';
        return;
      }
      
      const expressions = detections[0].expressions;
      let infoHTML = '<h3>í‘œì • ë¶„ì„ ê²°ê³¼:</h3>';
      infoHTML += '<div style="display: flex; flex-wrap: wrap; justify-content: center;">';
      
      Object.entries(expressions).forEach(([emotion, confidence]) => {
        const percent = (confidence * 100).toFixed(1);
        const emoji = {
          'happy': 'ğŸ˜„', 'sad': 'ğŸ˜¢', 'angry': 'ğŸ˜ ', 'fearful': 'ğŸ˜¨',
          'disgusted': 'ğŸ¤¢', 'surprised': 'ğŸ˜²', 'neutral': 'ğŸ˜'
        }[emotion] || 'â“';
        
        infoHTML += `
          <div style="margin: 5px; padding: 8px; background: #333; border-radius: 5px; min-width: 100px;">
            <div>${emoji} ${emotion}</div>
            <div>${percent}%</div>
          </div>
        `;
      });
      
      infoHTML += '</div>';
      detectionInfo.innerHTML = infoHTML;
    }

    function capturePhoto() {
      if (!isCameraActive) {
        alert('ë¨¼ì € ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”!');
        return;
      }
      
      try {
        const link = document.createElement('a');
        link.href = overlay.toDataURL('image/png');
        link.download = `smile_${new Date().getTime()}.png`;
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
        
        updateStatus('ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!', 'success');
      } catch (error) {
        updateStatus('ì‚¬ì§„ ì €ì¥ ì‹¤íŒ¨: ' + error.message, 'error');
      }
    }

    startCameraBtn.addEventListener('click', startCamera);
    captureBtn.addEventListener('click', capturePhoto);
    window.addEventListener('load', loadModels);
    window.addEventListener('beforeunload', () => {
      if (detectionInterval) clearInterval(detectionInterval);
      if (video.srcObject) video.srcObject.getTracks().forEach(track => track.stop());
    });
  </script>
</body>
</html>
